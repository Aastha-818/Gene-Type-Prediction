{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1QRiku6gNmv",
        "outputId": "d6822a06-2bf9-482d-b1de-e9b6b3b8ad98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Drive mounted successfully.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,\n",
        "    Bidirectional,\n",
        "    LSTM,\n",
        "    Conv1D,\n",
        "    Dropout,\n",
        "    BatchNormalization,\n",
        "    Input,\n",
        ")\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Drive mounted successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psKDdCfniCFd",
        "outputId": "addd7d43-20dd-4bc4-b345-83a32f164742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing /content/drive/MyDrive/gene type project/gene dataset/train.csv...\n",
            "Generated X shape: (8036894, 4, 5)\n",
            "Generated y shape: (8036894, 5)\n",
            "Processing /content/drive/MyDrive/gene type project/gene dataset/validation.csv...\n",
            "Generated X shape: (1641930, 4, 5)\n",
            "Generated y shape: (1641930, 5)\n",
            "Processing /content/drive/MyDrive/gene type project/gene dataset/test.csv...\n",
            "Generated X shape: (3009781, 4, 5)\n",
            "Generated y shape: (3009781, 5)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# We define a 5-character vocabulary to include 'N'\n",
        "VOCAB = \"ACGTN\"\n",
        "char_to_int = {char: i for i, char in enumerate(VOCAB)}\n",
        "int_to_char = {i: char for i, char in enumerate(VOCAB)}\n",
        "NUM_CLASSES = len(VOCAB)\n",
        "SEQUENCE_LENGTH = 4  # Predict the 5th nucleotide\n",
        "\n",
        "\n",
        "def preprocess_data(filepath):\n",
        "    \"\"\"Loads a CSV, cleans it, and prepares (X, y) for the model.\"\"\"\n",
        "    print(f\"Processing {filepath}...\")\n",
        "    try:\n",
        "        # Load the data\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # Clean the sequences\n",
        "        # Remove '<' and '>' characters\n",
        "        df[\"NucleotideSequence\"] = df[\"NucleotideSequence\"].str.strip(\"<>\")\n",
        "        # Filter out any non-ACGTN characters (just in case)\n",
        "        df[\"CleanSequence\"] = df[\"NucleotideSequence\"].apply(\n",
        "            lambda seq: \"\".join([char for char in seq.upper() if char in VOCAB])\n",
        "        )\n",
        "\n",
        "        # Create integer sequences\n",
        "        df[\"IntegerSequence\"] = df[\"CleanSequence\"].apply(\n",
        "            lambda seq: [char_to_int[char] for char in seq]\n",
        "        )\n",
        "\n",
        "        # Prepare (X, y) pairs\n",
        "        X_list = []\n",
        "        y_list = []\n",
        "\n",
        "        for seq in df[\"IntegerSequence\"]:\n",
        "            # Create sliding windows of size (SEQUENCE_LENGTH + 1)\n",
        "            for i in range(len(seq) - SEQUENCE_LENGTH):\n",
        "                X_list.append(seq[i : i + SEQUENCE_LENGTH])\n",
        "                y_list.append(seq[i + SEQUENCE_LENGTH])\n",
        "\n",
        "        if not X_list:\n",
        "            print(f\"Warning: No valid sequences found in {filepath}\")\n",
        "            return (\n",
        "                np.array([]).reshape(0, SEQUENCE_LENGTH, NUM_CLASSES),\n",
        "                np.array([]).reshape(0, NUM_CLASSES),\n",
        "            )\n",
        "\n",
        "        # Convert lists to numpy arrays\n",
        "        X_np = np.array(X_list)\n",
        "        y_np = np.array(y_list)\n",
        "\n",
        "        # One-hot encode X and y\n",
        "        X_one_hot = to_categorical(X_np, num_classes=NUM_CLASSES)\n",
        "        y_one_hot = to_categorical(y_np, num_classes=NUM_CLASSES)\n",
        "\n",
        "        print(f\"Generated X shape: {X_one_hot.shape}\")\n",
        "        print(f\"Generated y shape: {y_one_hot.shape}\")\n",
        "\n",
        "        return X_one_hot, y_one_hot\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {filepath}\")\n",
        "        print(\"Please ensure the Google Drive path is correct and the file exists.\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing {filepath}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "# --- 3. Load and Process Data Using Your Drive Paths ---\n",
        "\n",
        "# *** UPDATED FILE PATHS ***\n",
        "train_file = \"/content/drive/MyDrive/gene type project/gene dataset/train.csv\"\n",
        "val_file = \"/content/drive/MyDrive/gene type project/gene dataset/validation.csv\"\n",
        "test_file = \"/content/drive/MyDrive/gene type project/gene dataset/test.csv\"\n",
        "\n",
        "X_train, y_train = preprocess_data(train_file)\n",
        "X_val, y_val = preprocess_data(val_file)\n",
        "X_test, y_test = preprocess_data(test_file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "TB3ic0-bi8TR",
        "outputId": "b9897bf3-914d-44ef-e081-6cb76a17b19e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m263,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m164,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">438,661</span> (1.67 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m438,661\u001b[0m (1.67 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">438,405</span> (1.67 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m438,405\u001b[0m (1.67 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- 4. Define an Improved Model ---\n",
        "\n",
        "# A more robust model architecture\n",
        "model = Sequential(\n",
        "    [\n",
        "        Input(shape=(SEQUENCE_LENGTH, NUM_CLASSES)),\n",
        "        # 1D Conv layer to find local patterns (motifs)\n",
        "        Conv1D(\n",
        "            filters=128,\n",
        "            kernel_size=3,\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "        ),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        # Bidirectional LSTMs to learn sequence context\n",
        "        Bidirectional(LSTM(128, return_sequences=True)),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(LSTM(64)),\n",
        "        Dropout(0.3),\n",
        "        # Dense layer for final classification\n",
        "        Dense(64, activation=\"relu\"),\n",
        "        # Output layer MUST have 5 units for (A, C, G, T, N)\n",
        "        Dense(NUM_CLASSES, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewn-EyDUjB6x",
        "outputId": "f35feaf7-12c8-47e4-a113-51c9a3339003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Model Training ---\n",
            "Epoch 1/50\n",
            "\u001b[1m61209/62789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:32\u001b[0m 59ms/step - accuracy: 0.3247 - loss: 1.3455"
          ]
        }
      ],
      "source": [
        "# --- 5. Set Up Callbacks (Including Model Saving) ---\n",
        "\n",
        "# Save the *best* performing model based on validation accuracy\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=\"best_dna_model.keras\",  # This will save to your Colab instance\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\",\n",
        "    save_best_only=True,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Stop training early if the model stops improving\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    patience=5,  # Stop after 5 epochs of no improvement\n",
        "    restore_best_weights=True,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# --- 6. Train the Model ---\n",
        "\n",
        "# Check if data was loaded successfully before training\n",
        "if X_train is not None and X_val is not None:\n",
        "    print(\"\\n--- Starting Model Training ---\")\n",
        "    history = model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        epochs=20,  # Train for more epochs; EarlyStopping will find the best one\n",
        "        batch_size=512,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=[checkpoint_callback, early_stopping_callback],\n",
        "    )\n",
        "\n",
        "    # --- 7. Evaluate and Save Final Model ---\n",
        "    if X_test is not None:\n",
        "        print(\"\\n--- Evaluating Model on Test Data ---\")\n",
        "        test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "        print(f\"Test Loss: {test_loss:.4f}\")\n",
        "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Save the final model\n",
        "    model.save(\"final_dna_model.keras\")\n",
        "    print(\"\\nBest model saved as 'best_dna_model.keras'\")\n",
        "    print(\"Final model saved as 'final_dna_model.keras'\")\n",
        "    print(\"You can find these saved models in the Colab file browser.\")\n",
        "else:\n",
        "    print(\"\\n--- Model Training Skipped ---\")\n",
        "    print(\"Training was skipped because one or more data files could not be loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSE04l3_on4c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}